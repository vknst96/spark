apiVersion: v1
kind: ConfigMap
metadata:
  labels:
    app-name: spark-on-eks-client-mode-res1
  name: spark-on-eks-client-mode-res1-cm
  namespace: spark
data:
  spark.kubernetes.namespace: spark
  spark.properties: |
    spark.app.name=spark-on-eks-example
    spark.submit.deployMode=client

    # should be the url of k8s cluster
    spark.master=k8s\://https\://B72A36CD02AF116560CA57F3D21709D8.gr7.us-east-1.eks.amazonaws.com\:443

    spark.kubernetes.container.image=vknstudy96/pyspark-app\:v1
    spark.kubernetes.container.image.pullPolicy=Always

    spark.kubernetes.driver.pod.name=spark-on-eks-client-mode-res1-driver
    
    # should match the headless service name
    spark.driver.host=spark-on-eks-client-mode-res1-svc.spark.svc
    spark.driver.port=7078
    spark.driver.blockManager.port=7079

    spark.kubernetes.authenticate.driver.serviceAccountName=spark
    spark.kubernetes.namespace=spark
    
    # if providing files
    spark.submit.pyFiles=local\:///opt/spark/work-dir/functions.py

    spark.kubernetes.node.selector.topology.kubernetes.io/zone=us-east-1a
    spark.kubernetes.node.selector.noderole=spark
    spark.kubernetes.driver.label.spark/app=spark-eks
    spark.kubernetes.driver.label.spark/component=driver
    spark.kubernetes.executor.label.spark/app=spark-eks
    spark.kubernetes.executor.label.spark/component=executor

    spark.kubernetes.resource.type=python

    spark.kubernetes.file.upload.path=s3a\://mysourcecodebkt/dynamic/
    spark.hadoop.fs.s3a.committer.name=magic
    spark.hadoop.fs.s3.impl=org.apache.hadoop.fs.s3a.S3AFileSystem
    spark.hadoop.fs.s3a.impl=org.apache.hadoop.fs.s3a.S3AFileSystem
    spark.hadoop.mapreduce.outputcommitter.factory.scheme.s3a=org.apache.hadoop.fs.s3a.commit.S3ACommitterFactory
    spark.hadoop.fs.s3a.committer.magic.enabled=true
    spark.hadoop.fs.s3a.aws.credentials.provider=com.amazonaws.auth.WebIdentityTokenCredentialsProvider
    spark.hadoop.fs.s3a.fast.upload=true

    
    spark.kubernetes.submitInDriver=true
    
    # should be path of pod template as its available inside driver container 
    spark.kubernetes.executor.podTemplateFile=/opt/spark/pod-template/executor-pod-spec-template.yml
    
    spark.executor.memory=2G
    spark.driver.memory=2G
    spark.sql.shuffle.partitions=20
    spark.executor.cores=1
    spark.kubernetes.memoryOverheadFactor=0.4
    spark.kubernetes.allocation.batch.size=10
